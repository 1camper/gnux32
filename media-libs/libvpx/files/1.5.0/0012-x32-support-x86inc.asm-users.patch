From 95adaaeb9c10597b61e11b692cd1064b46ada192 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Matthias=20R=C3=A4ncker?= <theonetruecamper@gmx.de>
Date: Sun, 16 Sep 2018 15:32:49 +0200
Subject: [PATCH 12/12] x32 support: x86inc.asm users
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Signed-off-by: Matthias RÃ¤ncker <theonetruecamper@gmx.de>
Change-Id: Ia846bd73657461699d6f6a6d8951f273aa9ea721
---
 vp9/encoder/x86/vp9_dct_mmx.asm                  |  2 +-
 vp9/encoder/x86/vp9_dct_ssse3_x86_64.asm         |  2 +-
 vp9/encoder/x86/vp9_error_sse2.asm               |  6 +-
 vp9/encoder/x86/vp9_highbd_error_avx.asm         |  2 +-
 vp9/encoder/x86/vp9_highbd_error_sse2.asm        |  2 +-
 vp9/encoder/x86/vp9_quantize_ssse3_x86_64.asm    | 33 ++++-----
 vpx_dsp/x86/fwd_txfm_ssse3_x86_64.asm            |  2 +-
 vpx_dsp/x86/highbd_intrapred_sse2.asm            | 24 +++---
 vpx_dsp/x86/highbd_sad4d_sse2.asm                | 22 +++---
 vpx_dsp/x86/highbd_sad_sse2.asm                  | 20 ++---
 vpx_dsp/x86/highbd_subpel_variance_impl_sse2.asm | 93 ++++++++++++-----------
 vpx_dsp/x86/intrapred_sse2.asm                   | 48 ++++++------
 vpx_dsp/x86/intrapred_ssse3.asm                  | 44 +++++------
 vpx_dsp/x86/inv_txfm_ssse3_x86_64.asm            |  4 +-
 vpx_dsp/x86/inv_wht_sse2.asm                     |  2 +-
 vpx_dsp/x86/quantize_avx_x86_64.asm              | 75 ++++++++++---------
 vpx_dsp/x86/quantize_ssse3_x86_64.asm            | 37 +++++-----
 vpx_dsp/x86/sad4d_sse2.asm                       | 24 +++---
 vpx_dsp/x86/sad_sse2.asm                         | 19 ++---
 vpx_dsp/x86/subpel_variance_sse2.asm             | 94 ++++++++++++------------
 vpx_dsp/x86/subtract_sse2.asm                    | 31 ++++----
 vpx_dsp/x86/vpx_convolve_copy_sse2.asm           |  6 +-
 vpx_dsp/x86/vpx_subpixel_8t_ssse3.asm            | 16 ++--
 23 files changed, 302 insertions(+), 306 deletions(-)

diff --git a/vp9/encoder/x86/vp9_dct_mmx.asm b/vp9/encoder/x86/vp9_dct_mmx.asm
index 7a7a6b655..84c4d307a 100644
--- a/vp9/encoder/x86/vp9_dct_mmx.asm
+++ b/vp9/encoder/x86/vp9_dct_mmx.asm
@@ -48,7 +48,7 @@ SECTION .text
 %endmacro
 
 INIT_MMX mmx
-cglobal fwht4x4, 3, 4, 8, input, output, stride
+cglobal fwht4x4, 3, 4, 8, "p", input, "p", output, "d-", stride
   lea             r3q,       [inputq + strideq*4]
   movq            m0,        [inputq] ;a1
   movq            m1,        [inputq + strideq*2] ;b1
diff --git a/vp9/encoder/x86/vp9_dct_ssse3_x86_64.asm b/vp9/encoder/x86/vp9_dct_ssse3_x86_64.asm
index 74c52df19..66c7d5c25 100644
--- a/vp9/encoder/x86/vp9_dct_ssse3_x86_64.asm
+++ b/vp9/encoder/x86/vp9_dct_ssse3_x86_64.asm
@@ -88,7 +88,7 @@ SECTION .text
 %endmacro
 
 INIT_XMM ssse3
-cglobal hadamard_8x8, 3, 5, 10, input, stride, output
+cglobal hadamard_8x8, 3, 5, 10, "p", input, "d-", stride, "p", output
   lea                r3, [2 * strideq]
   lea                r4, [4 * strideq]
 
diff --git a/vp9/encoder/x86/vp9_error_sse2.asm b/vp9/encoder/x86/vp9_error_sse2.asm
index 5b0238272..d0c3bc9ba 100644
--- a/vp9/encoder/x86/vp9_error_sse2.asm
+++ b/vp9/encoder/x86/vp9_error_sse2.asm
@@ -18,7 +18,7 @@ SECTION .text
 ;                         int64_t *ssz)
 
 INIT_XMM sse2
-cglobal block_error, 3, 3, 8, uqc, dqc, size, ssz
+cglobal block_error, 3, 3, 8, "p", uqc, "p", dqc, "p-", size, "p", ssz
   pxor      m4, m4                 ; sse accumulator
   pxor      m6, m6                 ; ssz accumulator
   pxor      m5, m5                 ; dedicated zero register
@@ -77,10 +77,10 @@ cglobal block_error, 3, 3, 8, uqc, dqc, size, ssz
 
 ; Compute the sum of squared difference between two int16_t vectors.
 ; int64_t vp9_block_error_fp(int16_t *coeff, int16_t *dqcoeff,
-;                            intptr_t block_size)
+;                            int block_size)
 
 INIT_XMM sse2
-cglobal block_error_fp, 3, 3, 6, uqc, dqc, size
+cglobal block_error_fp, 3, 3, 6, "p", uqc, "p", dqc, "d-", size
   pxor      m4, m4                 ; sse accumulator
   pxor      m5, m5                 ; dedicated zero register
   lea     uqcq, [uqcq+sizeq*2]
diff --git a/vp9/encoder/x86/vp9_highbd_error_avx.asm b/vp9/encoder/x86/vp9_highbd_error_avx.asm
index e476323e1..699ff96e0 100644
--- a/vp9/encoder/x86/vp9_highbd_error_avx.asm
+++ b/vp9/encoder/x86/vp9_highbd_error_avx.asm
@@ -21,7 +21,7 @@ ALIGN 16
 ;
 
 INIT_XMM avx
-cglobal highbd_block_error_8bit, 4, 5, 8, uqc, dqc, size, ssz
+cglobal highbd_block_error_8bit, 4, 5, 8, "p", uqc, "p", dqc, "p-", size, "p", ssz
   vzeroupper
 
   ; If only one iteration is required, then handle this as a special case.
diff --git a/vp9/encoder/x86/vp9_highbd_error_sse2.asm b/vp9/encoder/x86/vp9_highbd_error_sse2.asm
index f3b8f0194..902e02d70 100644
--- a/vp9/encoder/x86/vp9_highbd_error_sse2.asm
+++ b/vp9/encoder/x86/vp9_highbd_error_sse2.asm
@@ -21,7 +21,7 @@ ALIGN 16
 ;
 
 INIT_XMM sse2
-cglobal highbd_block_error_8bit, 3, 3, 8, uqc, dqc, size, ssz
+cglobal highbd_block_error_8bit, 3, 3, 8, "p", uqc, "p", dqc, "p-", size, "p", ssz
   pxor      m4, m4                 ; sse accumulator
   pxor      m6, m6                 ; ssz accumulator
   pxor      m5, m5                 ; dedicated zero register
diff --git a/vp9/encoder/x86/vp9_quantize_ssse3_x86_64.asm b/vp9/encoder/x86/vp9_quantize_ssse3_x86_64.asm
index 9af6ccb7f..50f795547 100644
--- a/vp9/encoder/x86/vp9_quantize_ssse3_x86_64.asm
+++ b/vp9/encoder/x86/vp9_quantize_ssse3_x86_64.asm
@@ -18,19 +18,16 @@ pw_1: times 8 dw 1
 SECTION .text
 
 %macro QUANTIZE_FP 2
-cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
-                                shift, qcoeff, dqcoeff, dequant, \
-                                eob, scan, iscan
+cglobal quantize_%1, 0, %2, 15, "p", coeff, "p-", ncoeff, "d", skip, \
+                                "p", zbin, "p", round, "p", quant, "p", shift, \
+                                "p", qcoeff, "p", dqcoeff, "p", dequant, \
+                                "p", eob, "p", scan, "p", iscan
   cmp                    dword skipm, 0
   jne .blank
 
   ; actual quantize loop - setup pointers, rounders, etc.
-  movifnidn                   coeffq, coeffmp
-  movifnidn                  ncoeffq, ncoeffmp
-  mov                             r2, dequantmp
-  movifnidn                    zbinq, zbinmp
-  movifnidn                   roundq, roundmp
-  movifnidn                   quantq, quantmp
+  ASSIGN_ARG dequant, skip
+  LOAD_ARG coeff, ncoeff, dequant, zbin, round, quant
   mova                            m1, [roundq]             ; m1 = round
   mova                            m2, [quantq]             ; m2 = quant
 %ifidn %1, fp_32x32
@@ -40,9 +37,10 @@ cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
   psrlw                           m1, 1                    ; m1 = (m1 + 1) / 2
 %endif
   mova                            m3, [r2q]                ; m3 = dequant
-  mov                             r3, qcoeffmp
-  mov                             r4, dqcoeffmp
-  mov                             r5, iscanmp
+  ASSIGN_ARG qcoeff, 3
+  ASSIGN_ARG dqcoeff, 4
+  ASSIGN_ARG iscan, 5
+  LOAD_ARG qcoeff, dqcoeff, iscan
 %ifidn %1, fp_32x32
   psllw                           m2, 1
 %endif
@@ -163,7 +161,8 @@ cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
 
 .accumulate_eob:
   ; horizontally accumulate/max eobs and write into [eob] memory pointer
-  mov                             r2, eobmp
+  ASSIGN_ARG eob, 2
+  LOAD_ARG eob
   pshufd                          m7, m8, 0xe
   pmaxsw                          m8, m7
   pshuflw                         m7, m8, 0xe
@@ -176,10 +175,10 @@ cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
 
   ; skip-block, i.e. just write all zeroes
 .blank:
-  mov                             r0, dqcoeffmp
-  movifnidn                  ncoeffq, ncoeffmp
-  mov                             r2, qcoeffmp
-  mov                             r3, eobmp
+  ASSIGN_ARG dqcoeff, 0
+  ASSIGN_ARG qcoeff, 2
+  ASSIGN_ARG eob, 3
+  LOAD_ARG dqcoeff, ncoeff, qcoeff, eob
 
   lea                            r0q, [r0q+ncoeffq*2]
   lea                            r2q, [r2q+ncoeffq*2]
diff --git a/vpx_dsp/x86/fwd_txfm_ssse3_x86_64.asm b/vpx_dsp/x86/fwd_txfm_ssse3_x86_64.asm
index 78a1dbb24..03208994e 100644
--- a/vpx_dsp/x86/fwd_txfm_ssse3_x86_64.asm
+++ b/vpx_dsp/x86/fwd_txfm_ssse3_x86_64.asm
@@ -128,7 +128,7 @@ SECTION .text
 %endmacro
 
 INIT_XMM ssse3
-cglobal fdct8x8, 3, 5, 13, input, output, stride
+cglobal fdct8x8, 3, 5, 13, "p", input, "p", output, "d-", stride
 
   mova               m8, [pd_8192]
   mova              m12, [pw_11585x2]
diff --git a/vpx_dsp/x86/highbd_intrapred_sse2.asm b/vpx_dsp/x86/highbd_intrapred_sse2.asm
index b12d29c0a..5d77dc69a 100644
--- a/vpx_dsp/x86/highbd_intrapred_sse2.asm
+++ b/vpx_dsp/x86/highbd_intrapred_sse2.asm
@@ -18,7 +18,7 @@ pw_32: times 4 dd 32
 
 SECTION .text
 INIT_MMX sse
-cglobal highbd_dc_predictor_4x4, 4, 5, 4, dst, stride, above, left, goffset
+cglobal highbd_dc_predictor_4x4, 4, 4, 4, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   movq                  m0, [aboveq]
@@ -45,7 +45,7 @@ cglobal highbd_dc_predictor_4x4, 4, 5, 4, dst, stride, above, left, goffset
   RET
 
 INIT_XMM sse2
-cglobal highbd_dc_predictor_8x8, 4, 5, 4, dst, stride, above, left, goffset
+cglobal highbd_dc_predictor_8x8, 4, 4, 4, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -80,7 +80,7 @@ cglobal highbd_dc_predictor_8x8, 4, 5, 4, dst, stride, above, left, goffset
   RET
 
 INIT_XMM sse2
-cglobal highbd_dc_predictor_16x16, 4, 5, 5, dst, stride, above, left, goffset
+cglobal highbd_dc_predictor_16x16, 4, 4, 5, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -124,7 +124,7 @@ cglobal highbd_dc_predictor_16x16, 4, 5, 5, dst, stride, above, left, goffset
 
 %if ARCH_X86_64
 INIT_XMM sse2
-cglobal highbd_dc_predictor_32x32, 4, 5, 9, dst, stride, above, left, goffset
+cglobal highbd_dc_predictor_32x32, 4, 4, 9, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -184,7 +184,7 @@ cglobal highbd_dc_predictor_32x32, 4, 5, 9, dst, stride, above, left, goffset
 %endif
 
 INIT_MMX sse
-cglobal highbd_v_predictor_4x4, 3, 3, 1, dst, stride, above
+cglobal highbd_v_predictor_4x4, 3, 3, 1, "p", dst, "p-", stride, "p", above
   movq                  m0, [aboveq]
   movq    [dstq          ], m0
   movq    [dstq+strideq*2], m0
@@ -194,7 +194,7 @@ cglobal highbd_v_predictor_4x4, 3, 3, 1, dst, stride, above
   RET
 
 INIT_XMM sse2
-cglobal highbd_v_predictor_8x8, 3, 3, 1, dst, stride, above
+cglobal highbd_v_predictor_8x8, 3, 3, 1, "p", dst, "p-", stride, "p", above
   mova                  m0, [aboveq]
   DEFINE_ARGS dst, stride, stride3
   lea             stride3q, [strideq*3]
@@ -210,7 +210,7 @@ cglobal highbd_v_predictor_8x8, 3, 3, 1, dst, stride, above
   RET
 
 INIT_XMM sse2
-cglobal highbd_v_predictor_16x16, 3, 4, 2, dst, stride, above
+cglobal highbd_v_predictor_16x16, 3, 4, 2, "p", dst, "p-", stride, "p", above
   mova                  m0, [aboveq]
   mova                  m1, [aboveq+16]
   DEFINE_ARGS dst, stride, stride3, nlines4
@@ -231,7 +231,7 @@ cglobal highbd_v_predictor_16x16, 3, 4, 2, dst, stride, above
   REP_RET
 
 INIT_XMM sse2
-cglobal highbd_v_predictor_32x32, 3, 4, 4, dst, stride, above
+cglobal highbd_v_predictor_32x32, 3, 4, 4, "p", dst, "p-", stride, "p", above
   mova                  m0, [aboveq]
   mova                  m1, [aboveq+16]
   mova                  m2, [aboveq+32]
@@ -262,7 +262,7 @@ cglobal highbd_v_predictor_32x32, 3, 4, 4, dst, stride, above
   REP_RET
 
 INIT_MMX sse
-cglobal highbd_tm_predictor_4x4, 5, 6, 5, dst, stride, above, left, bps, one
+cglobal highbd_tm_predictor_4x4, 5, 6, 5, "p", dst, "p-", stride, "p", above, "p", left, "d", bps, one
   movd                  m1, [aboveq-2]
   movq                  m0, [aboveq]
   pshufw                m1, m1, 0x0
@@ -300,7 +300,7 @@ cglobal highbd_tm_predictor_4x4, 5, 6, 5, dst, stride, above, left, bps, one
   REP_RET
 
 INIT_XMM sse2
-cglobal highbd_tm_predictor_8x8, 5, 6, 5, dst, stride, above, left, bps, one
+cglobal highbd_tm_predictor_8x8, 5, 6, 5, "p", dst, "p-", stride, "p", above, "p", left, "d", bps, one
   movd                  m1, [aboveq-2]
   mova                  m0, [aboveq]
   pshuflw               m1, m1, 0x0
@@ -345,7 +345,7 @@ cglobal highbd_tm_predictor_8x8, 5, 6, 5, dst, stride, above, left, bps, one
 
 %if ARCH_X86_64
 INIT_XMM sse2
-cglobal highbd_tm_predictor_16x16, 5, 6, 9, dst, stride, above, left, bps, one
+cglobal highbd_tm_predictor_16x16, 5, 6, 9, "p", dst, "p-", stride, "p", above, "p", left, "d", bps, one
   movd                  m2, [aboveq-2]
   mova                  m0, [aboveq]
   mova                  m1, [aboveq+16]
@@ -399,7 +399,7 @@ cglobal highbd_tm_predictor_16x16, 5, 6, 9, dst, stride, above, left, bps, one
   REP_RET
 
 INIT_XMM sse2
-cglobal highbd_tm_predictor_32x32, 5, 6, 12, dst, stride, above, left, bps, one
+cglobal highbd_tm_predictor_32x32, 5, 6, 12, "p", dst, "p-", stride, "p", above, "p", left, "d", bps, one
   movd                  m0, [aboveq-2]
   mova                  m1, [aboveq]
   mova                  m2, [aboveq+16]
diff --git a/vpx_dsp/x86/highbd_sad4d_sse2.asm b/vpx_dsp/x86/highbd_sad4d_sse2.asm
index 6c2a61e01..369110b33 100644
--- a/vpx_dsp/x86/highbd_sad4d_sse2.asm
+++ b/vpx_dsp/x86/highbd_sad4d_sse2.asm
@@ -215,11 +215,13 @@ SECTION .text
 ; where NxN = 64x64, 32x32, 16x16, 16x8, 8x16 or 8x8
 %macro HIGH_SADNXN4D 2
 %if UNIX64
-cglobal highbd_sad%1x%2x4d, 5, 8, 8, src, src_stride, ref1, ref_stride, \
-                              res, ref2, ref3, ref4
+cglobal highbd_sad%1x%2x4d, 5, 8, 8, "p", src, "d-", src_stride, \
+                                     "p", ref1, "d-", ref_stride, \
+                                     "p", res, ref2, ref3, ref4
 %else
-cglobal highbd_sad%1x%2x4d, 4, 7, 8, src, src_stride, ref1, ref_stride, \
-                              ref2, ref3, ref4
+cglobal highbd_sad%1x%2x4d, 4, 7, 8, "p", src, "d-", src_stride, \
+                                     "p", ref1, "d-", ref_stride, \
+                                     "p", ref2, ref3, ref4
 %endif
 
 ; set m1
@@ -229,12 +231,10 @@ cglobal highbd_sad%1x%2x4d, 4, 7, 8, src, src_stride, ref1, ref_stride, \
   pshufd                m1, m1, 0x0
   pop                 srcq
 
-  movsxdifnidn src_strideq, src_strided
-  movsxdifnidn ref_strideq, ref_strided
-  mov                ref2q, [ref1q+gprsize*1]
-  mov                ref3q, [ref1q+gprsize*2]
-  mov                ref4q, [ref1q+gprsize*3]
-  mov                ref1q, [ref1q+gprsize*0]
+  mov                ref2p, [ref1q+ptrsize*1]
+  mov                ref3p, [ref1q+ptrsize*2]
+  mov                ref4p, [ref1q+ptrsize*3]
+  mov                ref1p, [ref1q+ptrsize*0]
 
 ; convert byte pointers to short pointers
   shl                 srcq, 1
@@ -265,7 +265,7 @@ cglobal highbd_sad%1x%2x4d, 4, 7, 8, src, src_stride, ref1, ref_stride, \
   paddd                 m4, m0
   paddd                 m6, m1
   punpcklqdq            m4, m6
-  movifnidn             r4, r4mp
+  LOAD_ARG 4
   movu                [r4], m4
   RET
 %endmacro
diff --git a/vpx_dsp/x86/highbd_sad_sse2.asm b/vpx_dsp/x86/highbd_sad_sse2.asm
index bc4b28db2..dc5d62e6e 100644
--- a/vpx_dsp/x86/highbd_sad_sse2.asm
+++ b/vpx_dsp/x86/highbd_sad_sse2.asm
@@ -15,19 +15,23 @@ SECTION .text
 %macro HIGH_SAD_FN 4
 %if %4 == 0
 %if %3 == 5
-cglobal highbd_sad%1x%2, 4, %3, 7, src, src_stride, ref, ref_stride, n_rows
+cglobal highbd_sad%1x%2, 4, %3, 7, "p", src, "d-", src_stride, \
+                                   "p", ref, "d-", ref_stride, n_rows
 %else ; %3 == 7
-cglobal highbd_sad%1x%2, 4, %3, 7, src, src_stride, ref, ref_stride, \
+cglobal highbd_sad%1x%2, 4, %3, 7, "p", src, "d-", src_stride, \
+                                   "p", ref, "d-", ref_stride, \
                             src_stride3, ref_stride3, n_rows
 %endif ; %3 == 5/7
 %else ; avg
 %if %3 == 5
-cglobal highbd_sad%1x%2_avg, 5, 1 + %3, 7, src, src_stride, ref, ref_stride, \
-                                    second_pred, n_rows
+cglobal highbd_sad%1x%2_avg, 5, 1 + %3, 7, "p", src, "d-", src_stride, \
+                                           "p", ref, "d-", ref_stride, \
+                                           "p", second_pred, n_rows
 %else ; %3 == 7
-cglobal highbd_sad%1x%2_avg, 5, ARCH_X86_64 + %3, 7, src, src_stride, \
-                                              ref, ref_stride, \
-                                              second_pred, \
+cglobal highbd_sad%1x%2_avg, 5, ARCH_X86_64 + %3, 7, \
+                                           "p", src, "d-", src_stride, \
+                                           "p", ref, "d-", ref_stride, \
+                                           "p", second_pred, \
                                               src_stride3, ref_stride3
 %if ARCH_X86_64
 %define n_rowsd r7d
@@ -36,8 +40,6 @@ cglobal highbd_sad%1x%2_avg, 5, ARCH_X86_64 + %3, 7, src, src_stride, \
 %endif ; x86-32/64
 %endif ; %3 == 5/7
 %endif ; avg/sad
-  movsxdifnidn src_strideq, src_strided
-  movsxdifnidn ref_strideq, ref_strided
 %if %3 == 7
   lea         src_stride3q, [src_strideq*3]
   lea         ref_stride3q, [ref_strideq*3]
diff --git a/vpx_dsp/x86/highbd_subpel_variance_impl_sse2.asm b/vpx_dsp/x86/highbd_subpel_variance_impl_sse2.asm
index 52db60aaa..c4efdde7d 100644
--- a/vpx_dsp/x86/highbd_subpel_variance_impl_sse2.asm
+++ b/vpx_dsp/x86/highbd_subpel_variance_impl_sse2.asm
@@ -70,7 +70,7 @@ SECTION .text
   pshufd               m4, m6, 0x1
   paddd                m7, m3
   paddd                m6, m4
-  mov                  r1, ssem         ; r1 = unsigned int *sse
+  mov                 r1p, ssemp        ; r1 = unsigned int *sse
   movd               [r1], m7           ; store sse
   movd                rax, m6           ; store sum as return value
 %endif
@@ -93,71 +93,65 @@ SECTION .text
 
 %ifdef PIC    ; 64bit PIC
   %if %2 == 1 ; avg
-    cglobal highbd_sub_pixel_avg_variance%1xh, 9, 10, 13, src, src_stride, \
-                                      x_offset, y_offset, \
-                                      dst, dst_stride, \
-                                      sec, sec_stride, height, sse
+    cglobal highbd_sub_pixel_avg_variance%1xh, 9, 10, 13, \
+                                      "p", src, "p-", src_stride, \
+                                      "d", x_offset, "d", y_offset, \
+                                      "p", dst, "p-", dst_stride, \
+                                      "p", sec, "p-", sec_stride, \
+                                      "d", height, "p", sse
     %define sec_str sec_strideq
   %else
-    cglobal highbd_sub_pixel_variance%1xh, 7, 8, 13, src, src_stride, x_offset, \
-                                  y_offset, dst, dst_stride, height, sse
+    cglobal highbd_sub_pixel_variance%1xh, 7, 8, 13, \
+                                  "p", src, "p-", src_stride, \
+                                  "d", x_offset, "d", y_offset, \
+                                  "p", dst, "p-", dst_stride, \
+                                  "d", height, "p", sse
   %endif
   %define block_height heightd
   %define bilin_filter sseq
 %else
   %if ARCH_X86=1 && CONFIG_PIC=1
     %if %2 == 1 ; avg
-      cglobal highbd_sub_pixel_avg_variance%1xh, 7, 7, 13, src, src_stride, \
-                                  x_offset, y_offset, \
-                                  dst, dst_stride, \
-                                  sec, sec_stride, \
-                                  height, sse
+      cglobal highbd_sub_pixel_avg_variance%1xh, 7, 7, 13, \
+                                  "p*", src, "p-*", src_stride, \
+                                  "d", x_offset, "d", y_offset, \
+                                  "p", dst, "p-", dst_stride, \
+                                  "p", sec, "p-", sec_stride, \
+                                  "d", height, "p", sse
       %define block_height dword heightm
       %define sec_str sec_stridemp
-
-      ; reuse argument stack space
-      %define g_bilin_filterm x_offsetm
-      %define g_pw_8m y_offsetm
-
-      ; Store bilin_filter and pw_8 location in stack
-      GET_GOT_NO_SAVE eax
-
-      lea ecx, [GLOBAL(bilin_filter_m)]
-      mov g_bilin_filterm, ecx
-
-      lea ecx, [GLOBAL(pw_8)]
-      mov g_pw_8m, ecx
-
-      LOAD_IF_USED 0, 1         ; load eax, ecx back
     %else
-      cglobal highbd_sub_pixel_variance%1xh, 7, 7, 13, src, src_stride, \
-                                x_offset, y_offset, dst, dst_stride, height, \
-                                sse
+      cglobal highbd_sub_pixel_variance%1xh, 7, 7, 13, \
+                                  "p*", src, "p-*", src_stride, \
+                                  "d", x_offset, "d", y_offset, \
+                                  "p", dst, "p-", dst_stride, \
+                                  "d", height, "p", sse
       %define block_height heightd
+    %endif
 
-      ; reuse argument stack space
-      %define g_bilin_filterm x_offsetm
-      %define g_pw_8m y_offsetm
+    ; reuse argument stack space
+    %define g_bilin_filterm x_offsetm
+    %define g_pw_8m y_offsetm
 
-      ; Store bilin_filter and pw_8 location in stack
-      GET_GOT_NO_SAVE eax
+    ; Store bilin_filter and pw_8 location in stack
+    GET_GOT_NO_SAVE eax
 
-      lea ecx, [GLOBAL(bilin_filter_m)]
-      mov g_bilin_filterm, ecx
+    lea ecx, [GLOBAL(bilin_filter_m)]
+    mov g_bilin_filterm, ecx
 
-      lea ecx, [GLOBAL(pw_8)]
-      mov g_pw_8m, ecx
+    lea ecx, [GLOBAL(pw_8)]
+    mov g_pw_8m, ecx
 
-      LOAD_IF_USED 0, 1         ; load eax, ecx back
-    %endif
+    LOAD_ARG src, src_stride
   %else
     %if %2 == 1 ; avg
       cglobal highbd_sub_pixel_avg_variance%1xh, 7 + 2 * ARCH_X86_64, \
-                        7 + 2 * ARCH_X86_64, 13, src, src_stride, \
-                                             x_offset, y_offset, \
-                                             dst, dst_stride, \
-                                             sec, sec_stride, \
-                                             height, sse
+                        7 + 2 * ARCH_X86_64, 13, \
+                                             "p", src, "p-", src_stride, \
+                                             "d", x_offset, "d", y_offset, \
+                                             "p", dst, "p-", dst_stride, \
+                                             "p", sec, "p-", sec_stride, \
+                                             "d", height, "p", sse
       %if ARCH_X86_64
       %define block_height heightd
       %define sec_str sec_strideq
@@ -166,8 +160,11 @@ SECTION .text
       %define sec_str sec_stridemp
       %endif
     %else
-      cglobal highbd_sub_pixel_variance%1xh, 7, 7, 13, src, src_stride, \
-                              x_offset, y_offset, dst, dst_stride, height, sse
+      cglobal highbd_sub_pixel_variance%1xh, 7, 7, 13, \
+                                             "p", src, "p-", src_stride, \
+                                             "d", x_offset, "d", y_offset, \
+                                             "p", dst, "p-", dst_stride, \
+                                             "d", height, "p", sse
       %define block_height heightd
     %endif
 
diff --git a/vpx_dsp/x86/intrapred_sse2.asm b/vpx_dsp/x86/intrapred_sse2.asm
index 22b573188..2f4f19a3d 100644
--- a/vpx_dsp/x86/intrapred_sse2.asm
+++ b/vpx_dsp/x86/intrapred_sse2.asm
@@ -24,7 +24,7 @@ pw2_32:  times 8 dw 16
 SECTION .text
 
 INIT_MMX sse
-cglobal dc_predictor_4x4, 4, 5, 2, dst, stride, above, left, goffset
+cglobal dc_predictor_4x4, 4, 4, 2, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -45,7 +45,7 @@ cglobal dc_predictor_4x4, 4, 5, 2, dst, stride, above, left, goffset
   RET
 
 INIT_MMX sse
-cglobal dc_left_predictor_4x4, 4, 5, 2, dst, stride, above, left, goffset
+cglobal dc_left_predictor_4x4, 4, 4, 2, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -65,7 +65,7 @@ cglobal dc_left_predictor_4x4, 4, 5, 2, dst, stride, above, left, goffset
   RET
 
 INIT_MMX sse
-cglobal dc_top_predictor_4x4, 4, 5, 2, dst, stride, above, left, goffset
+cglobal dc_top_predictor_4x4, 4, 4, 2, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -85,7 +85,7 @@ cglobal dc_top_predictor_4x4, 4, 5, 2, dst, stride, above, left, goffset
   RET
 
 INIT_MMX sse
-cglobal dc_predictor_8x8, 4, 5, 3, dst, stride, above, left, goffset
+cglobal dc_predictor_8x8, 4, 4, 3, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -114,7 +114,7 @@ cglobal dc_predictor_8x8, 4, 5, 3, dst, stride, above, left, goffset
   RET
 
 INIT_MMX sse
-cglobal dc_top_predictor_8x8, 4, 5, 3, dst, stride, above, left, goffset
+cglobal dc_top_predictor_8x8, 4, 4, 3, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -140,7 +140,7 @@ cglobal dc_top_predictor_8x8, 4, 5, 3, dst, stride, above, left, goffset
   RET
 
 INIT_MMX sse
-cglobal dc_left_predictor_8x8, 4, 5, 3, dst, stride, above, left, goffset
+cglobal dc_left_predictor_8x8, 4, 4, 3, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -166,7 +166,7 @@ cglobal dc_left_predictor_8x8, 4, 5, 3, dst, stride, above, left, goffset
   RET
 
 INIT_MMX sse
-cglobal dc_128_predictor_4x4, 4, 5, 3, dst, stride, above, left, goffset
+cglobal dc_128_predictor_4x4, 4, 4, 3, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   DEFINE_ARGS dst, stride, stride3
@@ -180,7 +180,7 @@ cglobal dc_128_predictor_4x4, 4, 5, 3, dst, stride, above, left, goffset
   RET
 
 INIT_MMX sse
-cglobal dc_128_predictor_8x8, 4, 5, 3, dst, stride, above, left, goffset
+cglobal dc_128_predictor_8x8, 4, 4, 3, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   DEFINE_ARGS dst, stride, stride3
@@ -199,7 +199,7 @@ cglobal dc_128_predictor_8x8, 4, 5, 3, dst, stride, above, left, goffset
   RET
 
 INIT_XMM sse2
-cglobal dc_predictor_16x16, 4, 5, 3, dst, stride, above, left, goffset
+cglobal dc_predictor_16x16, 4, 4, 3, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -232,7 +232,7 @@ cglobal dc_predictor_16x16, 4, 5, 3, dst, stride, above, left, goffset
 
 
 INIT_XMM sse2
-cglobal dc_top_predictor_16x16, 4, 5, 3, dst, stride, above, left, goffset
+cglobal dc_top_predictor_16x16, 4, 4, 3, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -264,7 +264,7 @@ cglobal dc_top_predictor_16x16, 4, 5, 3, dst, stride, above, left, goffset
   REP_RET
 
 INIT_XMM sse2
-cglobal dc_left_predictor_16x16, 4, 5, 3, dst, stride, above, left, goffset
+cglobal dc_left_predictor_16x16, 4, 4, 3, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -296,7 +296,7 @@ cglobal dc_left_predictor_16x16, 4, 5, 3, dst, stride, above, left, goffset
   REP_RET
 
 INIT_XMM sse2
-cglobal dc_128_predictor_16x16, 4, 5, 3, dst, stride, above, left, goffset
+cglobal dc_128_predictor_16x16, 4, 4, 3, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   DEFINE_ARGS dst, stride, stride3, lines4
@@ -316,7 +316,7 @@ cglobal dc_128_predictor_16x16, 4, 5, 3, dst, stride, above, left, goffset
 
 
 INIT_XMM sse2
-cglobal dc_predictor_32x32, 4, 5, 5, dst, stride, above, left, goffset
+cglobal dc_predictor_32x32, 4, 4, 5, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -358,7 +358,7 @@ cglobal dc_predictor_32x32, 4, 5, 5, dst, stride, above, left, goffset
   REP_RET
 
 INIT_XMM sse2
-cglobal dc_top_predictor_32x32, 4, 5, 5, dst, stride, above, left, goffset
+cglobal dc_top_predictor_32x32, 4, 4, 5, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -394,7 +394,7 @@ cglobal dc_top_predictor_32x32, 4, 5, 5, dst, stride, above, left, goffset
   REP_RET
 
 INIT_XMM sse2
-cglobal dc_left_predictor_32x32, 4, 5, 5, dst, stride, above, left, goffset
+cglobal dc_left_predictor_32x32, 4, 4, 5, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   pxor                  m1, m1
@@ -430,7 +430,7 @@ cglobal dc_left_predictor_32x32, 4, 5, 5, dst, stride, above, left, goffset
   REP_RET
 
 INIT_XMM sse2
-cglobal dc_128_predictor_32x32, 4, 5, 3, dst, stride, above, left, goffset
+cglobal dc_128_predictor_32x32, 4, 4, 3, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
 
   DEFINE_ARGS dst, stride, stride3, lines4
@@ -453,7 +453,7 @@ cglobal dc_128_predictor_32x32, 4, 5, 3, dst, stride, above, left, goffset
   RET
 
 INIT_MMX sse
-cglobal v_predictor_4x4, 3, 3, 1, dst, stride, above
+cglobal v_predictor_4x4, 3, 3, 1, "p", dst, "p-", stride, "p", above
   movd                  m0, [aboveq]
   movd      [dstq        ], m0
   movd      [dstq+strideq], m0
@@ -463,7 +463,7 @@ cglobal v_predictor_4x4, 3, 3, 1, dst, stride, above
   RET
 
 INIT_MMX sse
-cglobal v_predictor_8x8, 3, 3, 1, dst, stride, above
+cglobal v_predictor_8x8, 3, 3, 1, "p", dst, "p-", stride, "p", above
   movq                  m0, [aboveq]
   DEFINE_ARGS dst, stride, stride3
   lea             stride3q, [strideq*3]
@@ -479,7 +479,7 @@ cglobal v_predictor_8x8, 3, 3, 1, dst, stride, above
   RET
 
 INIT_XMM sse2
-cglobal v_predictor_16x16, 3, 4, 1, dst, stride, above
+cglobal v_predictor_16x16, 3, 4, 1, "p", dst, "p-", stride, "p", above
   mova                  m0, [aboveq]
   DEFINE_ARGS dst, stride, stride3, nlines4
   lea             stride3q, [strideq*3]
@@ -495,7 +495,7 @@ cglobal v_predictor_16x16, 3, 4, 1, dst, stride, above
   REP_RET
 
 INIT_XMM sse2
-cglobal v_predictor_32x32, 3, 4, 2, dst, stride, above
+cglobal v_predictor_32x32, 3, 4, 2, "p", dst, "p-", stride, "p", above
   mova                  m0, [aboveq]
   mova                  m1, [aboveq+16]
   DEFINE_ARGS dst, stride, stride3, nlines4
@@ -516,7 +516,7 @@ cglobal v_predictor_32x32, 3, 4, 2, dst, stride, above
   REP_RET
 
 INIT_MMX sse
-cglobal tm_predictor_4x4, 4, 4, 4, dst, stride, above, left
+cglobal tm_predictor_4x4, 4, 4, 4, "p", dst, "p-", stride, "p", above, "p", left
   pxor                  m1, m1
   movd                  m2, [aboveq-1]
   movd                  m0, [aboveq]
@@ -546,7 +546,7 @@ cglobal tm_predictor_4x4, 4, 4, 4, dst, stride, above, left
   REP_RET
 
 INIT_XMM sse2
-cglobal tm_predictor_8x8, 4, 4, 4, dst, stride, above, left
+cglobal tm_predictor_8x8, 4, 4, 4, "p", dst, "p-", stride, "p", above, "p", left
   pxor                  m1, m1
   movd                  m2, [aboveq-1]
   movq                  m0, [aboveq]
@@ -578,7 +578,7 @@ cglobal tm_predictor_8x8, 4, 4, 4, dst, stride, above, left
   REP_RET
 
 INIT_XMM sse2
-cglobal tm_predictor_16x16, 4, 4, 7, dst, stride, above, left
+cglobal tm_predictor_16x16, 4, 4, 7, "p", dst, "p-", stride, "p", above, "p", left
   pxor                  m1, m1
   movd                  m2, [aboveq-1]
   mova                  m0, [aboveq]
@@ -616,7 +616,7 @@ cglobal tm_predictor_16x16, 4, 4, 7, dst, stride, above, left
 
 %if ARCH_X86_64
 INIT_XMM sse2
-cglobal tm_predictor_32x32, 4, 4, 10, dst, stride, above, left
+cglobal tm_predictor_32x32, 4, 4, 10, "p", dst, "p-", stride, "p", above, "p", left
   pxor                  m1, m1
   movd                  m2, [aboveq-1]
   mova                  m0, [aboveq]
diff --git a/vpx_dsp/x86/intrapred_ssse3.asm b/vpx_dsp/x86/intrapred_ssse3.asm
index 88df9b2d1..152d8c019 100644
--- a/vpx_dsp/x86/intrapred_ssse3.asm
+++ b/vpx_dsp/x86/intrapred_ssse3.asm
@@ -34,8 +34,7 @@ sh_b2333: db 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
 SECTION .text
 
 INIT_MMX ssse3
-cglobal h_predictor_4x4, 2, 4, 3, dst, stride, line, left
-  movifnidn          leftq, leftmp
+cglobal h_predictor_4x4, 4, 4, 3, "p", dst, "p-", stride, "p*", line, "p", left
   add                leftq, 4
   mov                lineq, -2
   pxor                  m0, m0
@@ -52,8 +51,7 @@ cglobal h_predictor_4x4, 2, 4, 3, dst, stride, line, left
   REP_RET
 
 INIT_MMX ssse3
-cglobal h_predictor_8x8, 2, 4, 3, dst, stride, line, left
-  movifnidn          leftq, leftmp
+cglobal h_predictor_8x8, 4, 4, 3, "p", dst, "p-", stride, "p*", line, "p", left
   add                leftq, 8
   mov                lineq, -4
   pxor                  m0, m0
@@ -70,8 +68,7 @@ cglobal h_predictor_8x8, 2, 4, 3, dst, stride, line, left
   REP_RET
 
 INIT_XMM ssse3
-cglobal h_predictor_16x16, 2, 4, 3, dst, stride, line, left
-  movifnidn          leftq, leftmp
+cglobal h_predictor_16x16, 4, 4, 3, "p", dst, "p-", stride, "p*", line, "p", left
   add                leftq, 16
   mov                lineq, -8
   pxor                  m0, m0
@@ -88,8 +85,7 @@ cglobal h_predictor_16x16, 2, 4, 3, dst, stride, line, left
   REP_RET
 
 INIT_XMM ssse3
-cglobal h_predictor_32x32, 2, 4, 3, dst, stride, line, left
-  movifnidn          leftq, leftmp
+cglobal h_predictor_32x32, 4, 4, 3, "p", dst, "p-", stride, "p*", line, "p", left
   add                leftq, 32
   mov                lineq, -16
   pxor                  m0, m0
@@ -108,7 +104,7 @@ cglobal h_predictor_32x32, 2, 4, 3, dst, stride, line, left
   REP_RET
 
 INIT_MMX ssse3
-cglobal d45_predictor_4x4, 3, 4, 4, dst, stride, above, goffset
+cglobal d45_predictor_4x4, 3, 3, 4, "p", dst, "p-", stride, "p", above, goffset
   GET_GOT     goffsetq
 
   movq                m0, [aboveq]
@@ -135,7 +131,7 @@ cglobal d45_predictor_4x4, 3, 4, 4, dst, stride, above, goffset
   RET
 
 INIT_MMX ssse3
-cglobal d45_predictor_8x8, 3, 4, 4, dst, stride, above, goffset
+cglobal d45_predictor_8x8, 3, 3, 4, "p", dst, "p-", stride, "p", above, goffset
   GET_GOT     goffsetq
 
   movq                m0, [aboveq]
@@ -174,7 +170,7 @@ cglobal d45_predictor_8x8, 3, 4, 4, dst, stride, above, goffset
   RET
 
 INIT_XMM ssse3
-cglobal d45_predictor_16x16, 3, 6, 4, dst, stride, above, dst8, line, goffset
+cglobal d45_predictor_16x16, 3, 5, 4, "p", dst, "p-", stride, "p", above, dst8, line, goffset
   GET_GOT     goffsetq
 
   mova                   m0, [aboveq]
@@ -225,7 +221,7 @@ cglobal d45_predictor_16x16, 3, 6, 4, dst, stride, above, dst8, line, goffset
   RET
 
 INIT_XMM ssse3
-cglobal d45_predictor_32x32, 3, 6, 7, dst, stride, above, dst16, line, goffset
+cglobal d45_predictor_32x32, 3, 5, 7, "p", dst, "p-", stride, "p", above, dst16, line, goffset
   GET_GOT     goffsetq
 
   mova                   m0, [aboveq]
@@ -320,7 +316,7 @@ cglobal d45_predictor_32x32, 3, 6, 7, dst, stride, above, dst16, line, goffset
 %endmacro
 
 INIT_XMM ssse3
-cglobal d63_predictor_4x4, 3, 4, 5, dst, stride, above, goffset
+cglobal d63_predictor_4x4, 3, 3, 5, "p", dst, "p-", stride, "p", above, goffset
   GET_GOT     goffsetq
 
   movq                m3, [aboveq]
@@ -342,7 +338,7 @@ cglobal d63_predictor_4x4, 3, 4, 5, dst, stride, above, goffset
   RET
 
 INIT_XMM ssse3
-cglobal d63_predictor_8x8, 3, 4, 5, dst, stride, above, goffset
+cglobal d63_predictor_8x8, 3, 3, 5, "p", dst, "p-", stride, "p", above, goffset
   GET_GOT     goffsetq
 
   movq                m3, [aboveq]
@@ -378,7 +374,7 @@ cglobal d63_predictor_8x8, 3, 4, 5, dst, stride, above, goffset
   RET
 
 INIT_XMM ssse3
-cglobal d63_predictor_16x16, 3, 5, 5, dst, stride, above, line, goffset
+cglobal d63_predictor_16x16, 3, 4, 5, "p", dst, "p-", stride, "p", above, line, goffset
   GET_GOT     goffsetq
 
   mova                m0, [aboveq]
@@ -408,7 +404,7 @@ cglobal d63_predictor_16x16, 3, 5, 5, dst, stride, above, line, goffset
   REP_RET
 
 INIT_XMM ssse3
-cglobal d63_predictor_32x32, 3, 5, 8, dst, stride, above, line, goffset
+cglobal d63_predictor_32x32, 3, 4, 8, "p", dst, "p-", stride, "p", above, line, goffset
   GET_GOT     goffsetq
 
   mova                   m0, [aboveq]
@@ -453,7 +449,7 @@ cglobal d63_predictor_32x32, 3, 5, 8, dst, stride, above, line, goffset
   REP_RET
 
 INIT_XMM ssse3
-cglobal d153_predictor_4x4, 4, 5, 4, dst, stride, above, left, goffset
+cglobal d153_predictor_4x4, 4, 4, 4, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
   movd                m0, [leftq]               ; l1, l2, l3, l4
   movd                m1, [aboveq-1]            ; tl, t1, t2, t3
@@ -485,7 +481,7 @@ cglobal d153_predictor_4x4, 4, 5, 4, dst, stride, above, left, goffset
   RET
 
 INIT_XMM ssse3
-cglobal d153_predictor_8x8, 4, 5, 8, dst, stride, above, left, goffset
+cglobal d153_predictor_8x8, 4, 4, 8, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
   movq                m0, [leftq]                     ; [0- 7] l1-8 [byte]
   movhps              m0, [aboveq-1]                  ; [8-15] tl, t1-7 [byte]
@@ -534,7 +530,7 @@ cglobal d153_predictor_8x8, 4, 5, 8, dst, stride, above, left, goffset
   RET
 
 INIT_XMM ssse3
-cglobal d153_predictor_16x16, 4, 5, 8, dst, stride, above, left, goffset
+cglobal d153_predictor_16x16, 4, 4, 8, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
   mova                m0, [leftq]
   movu                m7, [aboveq-1]
@@ -613,7 +609,7 @@ cglobal d153_predictor_16x16, 4, 5, 8, dst, stride, above, left, goffset
   RET
 
 INIT_XMM ssse3
-cglobal d153_predictor_32x32, 4, 5, 8, dst, stride, above, left, goffset
+cglobal d153_predictor_32x32, 4, 4, 8, "p", dst, "p-", stride, "p", above, "p", left, goffset
   GET_GOT     goffsetq
   mova                  m0, [leftq]
   movu                  m7, [aboveq-1]
@@ -790,7 +786,7 @@ cglobal d153_predictor_32x32, 4, 5, 8, dst, stride, above, left, goffset
   RET
 
 INIT_MMX ssse3
-cglobal d207_predictor_4x4, 4, 5, 4, dst, stride, unused, left, goffset
+cglobal d207_predictor_4x4, 4, 4, 4, "p", dst, "p-", stride, "p*", unused, "p", left, goffset
   GET_GOT     goffsetq
   movd                m0, [leftq]                ; abcd [byte]
   pshufb              m1, m0, [GLOBAL(sh_b1233)] ; bcdd [byte]
@@ -812,7 +808,7 @@ cglobal d207_predictor_4x4, 4, 5, 4, dst, stride, unused, left, goffset
   RET
 
 INIT_XMM ssse3
-cglobal d207_predictor_8x8, 4, 5, 4, dst, stride, stride3, left, goffset
+cglobal d207_predictor_8x8, 4, 4, 4, "p", dst, "p-", stride, "p*", stride3, "p", left, goffset
   GET_GOT     goffsetq
   movq                m3, [leftq]            ; abcdefgh [byte]
   lea           stride3q, [strideq*3]
@@ -846,7 +842,7 @@ cglobal d207_predictor_8x8, 4, 5, 4, dst, stride, stride3, left, goffset
   RET
 
 INIT_XMM ssse3
-cglobal d207_predictor_16x16, 4, 5, 5, dst, stride, stride3, left, goffset
+cglobal d207_predictor_16x16, 4, 4, 5, "p", dst, "p-", stride, "p*", stride3, "p", left, goffset
   GET_GOT     goffsetq
   lea           stride3q, [strideq*3]
   mova                m0, [leftq]            ; abcdefghijklmnop [byte]
@@ -893,7 +889,7 @@ cglobal d207_predictor_16x16, 4, 5, 5, dst, stride, stride3, left, goffset
   REP_RET
 
 INIT_XMM ssse3
-cglobal d207_predictor_32x32, 4, 5, 8, dst, stride, stride3, left, goffset
+cglobal d207_predictor_32x32, 4, 4, 8, "p", dst, "p-", stride, "p*", stride3, "p", left, goffset
   GET_GOT     goffsetq
   lea           stride3q, [strideq*3]
   mova                m1, [leftq]              ;  0-15 [byte]
diff --git a/vpx_dsp/x86/inv_txfm_ssse3_x86_64.asm b/vpx_dsp/x86/inv_txfm_ssse3_x86_64.asm
index 68e7fa40c..abdd6d304 100644
--- a/vpx_dsp/x86/inv_txfm_ssse3_x86_64.asm
+++ b/vpx_dsp/x86/inv_txfm_ssse3_x86_64.asm
@@ -153,7 +153,7 @@ SECTION .text
 
 INIT_XMM ssse3
 ; full inverse 8x8 2D-DCT transform
-cglobal idct8x8_64_add, 3, 5, 13, input, output, stride
+cglobal idct8x8_64_add, 3, 5, 13, "p", input, "p", output, "d-", stride
   mova     m8, [pd_8192]
   mova    m11, [pw_16]
   mova    m12, [pw_11585x2]
@@ -186,7 +186,7 @@ cglobal idct8x8_64_add, 3, 5, 13, input, output, stride
   RET
 
 ; inverse 8x8 2D-DCT transform with only first 10 coeffs non-zero
-cglobal idct8x8_12_add, 3, 5, 13, input, output, stride
+cglobal idct8x8_12_add, 3, 5, 13, "p", input, "p", output, "d-", stride
   mova       m8, [pd_8192]
   mova      m11, [pw_16]
   mova      m12, [pw_11585x2]
diff --git a/vpx_dsp/x86/inv_wht_sse2.asm b/vpx_dsp/x86/inv_wht_sse2.asm
index df6f4692b..9a17b7584 100644
--- a/vpx_dsp/x86/inv_wht_sse2.asm
+++ b/vpx_dsp/x86/inv_wht_sse2.asm
@@ -81,7 +81,7 @@ SECTION .text
 %endmacro
 
 INIT_XMM sse2
-cglobal iwht4x4_16_add, 3, 3, 7, input, output, stride
+cglobal iwht4x4_16_add, 3, 3, 7, "p", input, "p", output, "d-", stride
   mova            m0,        [inputq +  0]
   mova            m1,        [inputq + 16]
 
diff --git a/vpx_dsp/x86/quantize_avx_x86_64.asm b/vpx_dsp/x86/quantize_avx_x86_64.asm
index 01c41291b..06026cc51 100644
--- a/vpx_dsp/x86/quantize_avx_x86_64.asm
+++ b/vpx_dsp/x86/quantize_avx_x86_64.asm
@@ -13,14 +13,15 @@
 SECTION .text
 
 %macro QUANTIZE_FN 2
-cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
-                                shift, qcoeff, dqcoeff, dequant, \
-                                eob, scan, iscan
+cglobal quantize_%1, 0, %2, 15, "p", coeff, "p-", ncoeff, "d", skip, \
+                                "p", zbin, "p", round, "p", quant, "p", shift, \
+                                "p", qcoeff, "p", dqcoeff, "p", dequant, \
+                                "p", eob, "p", scan, "p", iscan
 
   vzeroupper
 
   ; If we can skip this block, then just zero the output
-  cmp                         skipmp, 0
+  cmp                         skipmd, 0
   jne .blank
 
 %ifnidn %1, b_32x32
@@ -36,8 +37,7 @@ cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
 
 .single:
 
-  movifnidn                   coeffq, coeffmp
-  movifnidn                    zbinq, zbinmp
+  LOAD_ARG coeff, zbin
   mova                            m0, [zbinq]              ; m0 = zbin
 
   ; Get DC and first 15 AC coeffs - in this special case, that is all.
@@ -52,9 +52,10 @@ cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
   mova                           m10, [coeffq+16]          ; m10 = c[i]
 %endif
 
-  mov                             r0, eobmp                ; Output pointer
-  mov                             r1, qcoeffmp             ; Output pointer
-  mov                             r2, dqcoeffmp            ; Output pointer
+  ASSIGN_ARG eob, 0                                        ; Output pointer
+  ASSIGN_ARG qcoeff, 1                                     ; Output pointer
+  ASSIGN_ARG dqcoeff, 2                                    ; Output pointer
+  LOAD_ARG eob, qcoeff, dqcoeff
 
   pxor                            m5, m5                   ; m5 = dedicated zero
 
@@ -90,18 +91,15 @@ cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
 .single_nonzero:
 
   ; Actual quantization of size 16 block - setup pointers, rounders, etc.
-  movifnidn                       r4, roundmp
-  movifnidn                       r5, quantmp
-  mov                             r3, dequantmp
-  mov                             r6, shiftmp
+  ASSIGN_ARG dequant, 3
+  LOAD_ARG round, quant, dequant, shift
   mova                            m1, [r4]              ; m1 = round
   mova                            m2, [r5]              ; m2 = quant
   mova                            m3, [r3]              ; m3 = dequant
   mova                            m4, [r6]              ; m4 = shift
 
-  mov                             r3, iscanmp
-
-  DEFINE_ARGS eob, qcoeff, dqcoeff, iscan
+  ASSIGN_ARG iscan, 3
+  LOAD_ARG iscan
 
   ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
 
@@ -191,16 +189,14 @@ cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
 
 %endif ; %ifnidn %1, b_32x32
 
-DEFINE_ARGS coeff, ncoeff, skip, zbin, round, quant, shift, \
-            qcoeff, dqcoeff, dequant, eob, scan, iscan
+DEFINE_ARGS "p", coeff, "p-", ncoeff, "d", skip, \
+            "p", zbin, "p", round, "p", quant, "p", shift, \
+            "p", qcoeff, "p", dqcoeff, "p", dequant, \
+            "p", eob, "p", scan, "p", iscan
 
   ; Actual quantization loop - setup pointers, rounders, etc.
-  movifnidn                   coeffq, coeffmp
-  movifnidn                  ncoeffq, ncoeffmp
-  mov                             r2, dequantmp
-  movifnidn                    zbinq, zbinmp
-  movifnidn                   roundq, roundmp
-  movifnidn                   quantq, quantmp
+  ASSIGN_ARG dequant, 2
+  LOAD_ARG coeff, ncoeff, dequant, zbin, round, quant
   mova                            m0, [zbinq]              ; m0 = zbin
   mova                            m1, [roundq]             ; m1 = round
   mova                            m2, [quantq]             ; m2 = quant
@@ -214,11 +210,13 @@ DEFINE_ARGS coeff, ncoeff, skip, zbin, round, quant, shift, \
 %endif
   paddw                           m0, m4                   ; m0 = m0 + 1
 
-  mov                             r2, shiftmp
-  mov                             r3, qcoeffmp
+  ASSIGN_ARG shift, 2
+  ASSIGN_ARG qcoeff, 3
+  ASSIGN_ARG dqcoeff, 4
+  ASSIGN_ARG iscan, 5
+  LOAD_ARG shift, qcoeff
   mova                            m4, [r2]                 ; m4 = shift
-  mov                             r4, dqcoeffmp
-  mov                             r5, iscanmp
+  LOAD_ARG dqcoeff, iscan
 %ifidn %1, b_32x32
   psllw                           m4, 1
 %endif
@@ -394,8 +392,9 @@ DEFINE_ARGS coeff, ncoeff, skip, zbin, round, quant, shift, \
   add                        ncoeffq, mmsize
   jnz .ac_only_loop
 
+  ASSIGN_ARG eob, 2
   ; Horizontally accumulate/max eobs and write into [eob] memory pointer
-  mov                             r2, eobmp
+  LOAD_ARG eob
   pshufd                          m7, m8, 0xe
   pmaxsw                          m8, m7
   pshuflw                         m7, m8, 0xe
@@ -482,7 +481,7 @@ DEFINE_ARGS coeff, ncoeff, skip, zbin, round, quant, shift, \
   jnz .ac_only_loop
 
   ; Horizontally accumulate/max eobs and write into [eob] memory pointer
-  mov                             r2, eobmp
+  LOAD_ARG eob
   pshufd                          m7, m8, 0xe
   pmaxsw                          m8, m7
   pshuflw                         m7, m8, 0xe
@@ -497,15 +496,15 @@ DEFINE_ARGS coeff, ncoeff, skip, zbin, round, quant, shift, \
   ; Skip-block, i.e. just write all zeroes
 .blank:
 
-DEFINE_ARGS coeff, ncoeff, skip, zbin, round, quant, shift, \
-            qcoeff, dqcoeff, dequant, eob, scan, iscan
-
-  mov                             r0, dqcoeffmp
-  movifnidn                  ncoeffq, ncoeffmp
-  mov                             r2, qcoeffmp
-  mov                             r3, eobmp
+DEFINE_ARGS "p", coeff, "p-", ncoeff, "d", skip, \
+            "p", zbin, "p", round, "p", quant, "p", shift, \
+            "p", qcoeff, "p", dqcoeff, "p", dequant, \
+            "p", eob, "p", scan, "p", iscan
 
-DEFINE_ARGS dqcoeff, ncoeff, qcoeff, eob
+  ASSIGN_ARG dqcoeff, 0
+  ASSIGN_ARG qcoeff, 2
+  ASSIGN_ARG eob, 3
+  LOAD_ARG dqcoeff, ncoeff, qcoeff, eob
 
 %if CONFIG_VP9_HIGHBITDEPTH
   lea                       dqcoeffq, [dqcoeffq+ncoeffq*4]
diff --git a/vpx_dsp/x86/quantize_ssse3_x86_64.asm b/vpx_dsp/x86/quantize_ssse3_x86_64.asm
index b2319c2bd..9f7353146 100644
--- a/vpx_dsp/x86/quantize_ssse3_x86_64.asm
+++ b/vpx_dsp/x86/quantize_ssse3_x86_64.asm
@@ -17,19 +17,16 @@ SECTION .text
 
 ; TODO(yunqingwang)fix quantize_b code for skip=1 case.
 %macro QUANTIZE_FN 2
-cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
-                                shift, qcoeff, dqcoeff, dequant, \
-                                eob, scan, iscan
+cglobal quantize_%1, 0, %2, 15, "p", coeff, "p-", ncoeff, "d", skip, \
+                                "p", zbin, "p", round, "p", quant, "p", shift, \
+                                "p", qcoeff, "p", dqcoeff, "p", dequant, \
+                                "p", eob, "p", scan, "p", iscan
   cmp                    dword skipm, 0
   jne .blank
 
   ; actual quantize loop - setup pointers, rounders, etc.
-  movifnidn                   coeffq, coeffmp
-  movifnidn                  ncoeffq, ncoeffmp
-  mov                             r2, dequantmp
-  movifnidn                    zbinq, zbinmp
-  movifnidn                   roundq, roundmp
-  movifnidn                   quantq, quantmp
+  ASSIGN_ARG dequant, 2
+  LOAD_ARG coeff, ncoeff, dequant, zbin, round, quant
   mova                            m0, [zbinq]              ; m0 = zbin
   mova                            m1, [roundq]             ; m1 = round
   mova                            m2, [quantq]             ; m2 = quant
@@ -43,11 +40,13 @@ cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
 %endif
   mova                            m3, [r2q]                ; m3 = dequant
   psubw                           m0, [pw_1]
-  mov                             r2, shiftmp
-  mov                             r3, qcoeffmp
+  ASSIGN_ARG shift, 2
+  ASSIGN_ARG qcoeff, 3
+  ASSIGN_ARG dqcoeff, 4
+  ASSIGN_ARG iscan, 5
+  LOAD_ARG shift, qcoeff
   mova                            m4, [r2]                 ; m4 = shift
-  mov                             r4, dqcoeffmp
-  mov                             r5, iscanmp
+  LOAD_ARG dqcoeff, iscan
 %ifidn %1, b_32x32
   psllw                           m4, 1
 %endif
@@ -292,7 +291,8 @@ cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
 
 .accumulate_eob:
   ; horizontally accumulate/max eobs and write into [eob] memory pointer
-  mov                             r2, eobmp
+  ASSIGN_ARG eob, 2
+  LOAD_ARG eob
   pshufd                          m7, m8, 0xe
   pmaxsw                          m8, m7
   pshuflw                         m7, m8, 0xe
@@ -305,11 +305,10 @@ cglobal quantize_%1, 0, %2, 15, coeff, ncoeff, skip, zbin, round, quant, \
 
   ; skip-block, i.e. just write all zeroes
 .blank:
-  mov                             r0, dqcoeffmp
-  movifnidn                  ncoeffq, ncoeffmp
-  mov                             r2, qcoeffmp
-  mov                             r3, eobmp
-  DEFINE_ARGS dqcoeff, ncoeff, qcoeff, eob
+  ASSIGN_ARG dqcoeff, 0
+  ASSIGN_ARG qcoeff, 2
+  ASSIGN_ARG eob, 3
+  LOAD_ARG dqcoeff, ncoeff, qcoeff, eob
 %if CONFIG_VP9_HIGHBITDEPTH
   lea                       dqcoeffq, [dqcoeffq+ncoeffq*4]
   lea                        qcoeffq, [ qcoeffq+ncoeffq*4]
diff --git a/vpx_dsp/x86/sad4d_sse2.asm b/vpx_dsp/x86/sad4d_sse2.asm
index a2f0ae79e..278998729 100644
--- a/vpx_dsp/x86/sad4d_sse2.asm
+++ b/vpx_dsp/x86/sad4d_sse2.asm
@@ -173,18 +173,18 @@ SECTION .text
 ; where NxN = 64x64, 32x32, 16x16, 16x8, 8x16 or 8x8
 %macro SADNXN4D 2
 %if UNIX64
-cglobal sad%1x%2x4d, 5, 8, 8, src, src_stride, ref1, ref_stride, \
-                              res, ref2, ref3, ref4
+cglobal sad%1x%2x4d, 5, 8, 8, "p", src, "d-", src_stride, \
+                              "p", ref1, "d-", ref_stride, \
+                              "p", res, ref2, ref3, ref4
 %else
-cglobal sad%1x%2x4d, 4, 7, 8, src, src_stride, ref1, ref_stride, \
-                              ref2, ref3, ref4
+cglobal sad%1x%2x4d, 4, 7, 8, "p", src, "d-", src_stride, \
+                              "p", ref1, "d-", ref_stride, \
+                              "p", ref2, ref3, ref4
 %endif
-  movsxdifnidn src_strideq, src_strided
-  movsxdifnidn ref_strideq, ref_strided
-  mov                ref2q, [ref1q+gprsize*1]
-  mov                ref3q, [ref1q+gprsize*2]
-  mov                ref4q, [ref1q+gprsize*3]
-  mov                ref1q, [ref1q+gprsize*0]
+  mov                ref2p, [ref1q+ptrsize*1]
+  mov                ref3p, [ref1q+ptrsize*2]
+  mov                ref4p, [ref1q+ptrsize*3]
+  mov                ref1p, [ref1q+ptrsize*0]
 
   PROCESS_%1x2x4 1, 0, 0, src_strideq, ref_strideq, 1
 %rep (%2-4)/2
@@ -201,12 +201,12 @@ cglobal sad%1x%2x4d, 4, 7, 8, src, src_stride, ref1, ref_stride, \
   mova                  m7, m6
   punpcklqdq            m4, m6
   punpckhqdq            m5, m7
-  movifnidn             r4, r4mp
+  LOAD_ARG 4
   paddd                 m4, m5
   movu                [r4], m4
   RET
 %else
-  movifnidn             r4, r4mp
+  LOAD_ARG 4
   movq               [r4+0], m6
   movq               [r4+8], m7
   RET
diff --git a/vpx_dsp/x86/sad_sse2.asm b/vpx_dsp/x86/sad_sse2.asm
index 0defe1b6d..ddbeae181 100644
--- a/vpx_dsp/x86/sad_sse2.asm
+++ b/vpx_dsp/x86/sad_sse2.asm
@@ -15,19 +15,22 @@ SECTION .text
 %macro SAD_FN 4
 %if %4 == 0
 %if %3 == 5
-cglobal sad%1x%2, 4, %3, 5, src, src_stride, ref, ref_stride, n_rows
+cglobal sad%1x%2, 4, %3, 5, "p", src, "d-", src_stride, \
+                            "p", ref, "d-", ref_stride, n_rows
 %else ; %3 == 7
-cglobal sad%1x%2, 4, %3, 5, src, src_stride, ref, ref_stride, \
+cglobal sad%1x%2, 4, %3, 5, "p", src, "d-", src_stride, \
+                            "p", ref, "d-", ref_stride, \
                             src_stride3, ref_stride3, n_rows
 %endif ; %3 == 5/7
 %else ; avg
 %if %3 == 5
-cglobal sad%1x%2_avg, 5, 1 + %3, 5, src, src_stride, ref, ref_stride, \
-                                    second_pred, n_rows
+cglobal sad%1x%2_avg, 5, 1 + %3, 5, "p", src, "d-", src_stride, \
+                                    "p", ref, "d-", ref_stride, \
+                                    "p", second_pred, n_rows
 %else ; %3 == 7
-cglobal sad%1x%2_avg, 5, ARCH_X86_64 + %3, 5, src, src_stride, \
-                                              ref, ref_stride, \
-                                              second_pred, \
+cglobal sad%1x%2_avg, 5, ARCH_X86_64 + %3, 5, "p", src, "d-", src_stride, \
+                                              "p", ref, "d-", ref_stride, \
+                                              "p", second_pred, \
                                               src_stride3, ref_stride3
 %if ARCH_X86_64
 %define n_rowsd r7d
@@ -36,8 +39,6 @@ cglobal sad%1x%2_avg, 5, ARCH_X86_64 + %3, 5, src, src_stride, \
 %endif ; x86-32/64
 %endif ; %3 == 5/7
 %endif ; avg/sad
-  movsxdifnidn src_strideq, src_strided
-  movsxdifnidn ref_strideq, ref_strided
 %if %3 == 7
   lea         src_stride3q, [src_strideq*3]
   lea         ref_stride3q, [ref_strideq*3]
diff --git a/vpx_dsp/x86/subpel_variance_sse2.asm b/vpx_dsp/x86/subpel_variance_sse2.asm
index e82ead834..2d7b19b36 100644
--- a/vpx_dsp/x86/subpel_variance_sse2.asm
+++ b/vpx_dsp/x86/subpel_variance_sse2.asm
@@ -73,7 +73,7 @@ SECTION .text
   movhlps              m4, m6
   paddd                m7, m3
   paddd                m6, m4
-  mov                  r1, ssem         ; r1 = unsigned int *sse
+  mov                 r1p, ssemp        ; r1 = unsigned int *sse
   pshufd               m4, m6, 0x1
   movd               [r1], m7           ; store sse
   paddd                m6, m4
@@ -84,7 +84,7 @@ SECTION .text
   paddw                m6, m4
   paddd                m7, m3
   pcmpgtw              m5, m6           ; mask for 0 > x
-  mov                  r1, ssem         ; r1 = unsigned int *sse
+  mov                 r1p, ssemp        ; r1 = unsigned int *sse
   punpcklwd            m6, m5           ; sign-extend m6 word->dword
   movd               [r1], m7           ; store sse
   pshufw               m4, m6, 0xe
@@ -116,70 +116,65 @@ SECTION .text
 
 %ifdef PIC    ; 64bit PIC
   %if %2 == 1 ; avg
-    cglobal sub_pixel_avg_variance%1xh, 9, 10, 13, src, src_stride, \
-                                      x_offset, y_offset, \
-                                      dst, dst_stride, \
-                                      sec, sec_stride, height, sse
+    cglobal sub_pixel_avg_variance%1xh, 9, 10, 13, \
+                                      "p", src, "p-", src_stride, \
+                                      "d", x_offset, "d", y_offset, \
+                                      "p", dst, "p-", dst_stride, \
+                                      "p", sec, "p-", sec_stride, \
+                                      "d", height, "p", sse
     %define sec_str sec_strideq
   %else
-    cglobal sub_pixel_variance%1xh, 7, 8, 13, src, src_stride, x_offset, \
-                                  y_offset, dst, dst_stride, height, sse
+    cglobal sub_pixel_variance%1xh, 7, 8, 13, \
+                                  "p", src, "p-", src_stride, \
+                                  "d", x_offset, "d", y_offset, \
+                                  "p", dst, "p-", dst_stride, \
+                                  "d", height, "p", sse
   %endif
   %define block_height heightd
   %define bilin_filter sseq
 %else
   %if ARCH_X86=1 && CONFIG_PIC=1
     %if %2 == 1 ; avg
-      cglobal sub_pixel_avg_variance%1xh, 7, 7, 13, src, src_stride, \
-                                  x_offset, y_offset, \
-                                  dst, dst_stride, \
-                                  sec, sec_stride, \
-                                  height, sse
+      cglobal sub_pixel_avg_variance%1xh, 7, 7, 13, \
+                                      "p*", src, "p-*", src_stride, \
+                                      "d", x_offset, "d", y_offset, \
+                                      "p", dst, "p-", dst_stride, \
+                                      "p", sec, "p-", sec_stride, \
+                                      "d", height, "p", sse
       %define block_height dword heightm
       %define sec_str sec_stridemp
-
-      ; reuse argument stack space
-      %define g_bilin_filterm x_offsetm
-      %define g_pw_8m y_offsetm
-
-      ;Store bilin_filter and pw_8 location in stack
-      GET_GOT_NO_SAVE eax
-
-      lea ecx, [GLOBAL(bilin_filter_m)]
-      mov g_bilin_filterm, ecx
-
-      lea ecx, [GLOBAL(pw_8)]
-      mov g_pw_8m, ecx
-
-      LOAD_IF_USED 0, 1         ; load eax, ecx back
     %else
-      cglobal sub_pixel_variance%1xh, 7, 7, 13, src, src_stride, x_offset, \
-                                y_offset, dst, dst_stride, height, sse
+      cglobal sub_pixel_variance%1xh, 7, 7, 13, \
+                                  "p*", src, "p-*", src_stride, \
+                                  "d", x_offset, "d", y_offset, \
+                                  "p", dst, "p-", dst_stride, \
+                                  "d", height, "p", sse
       %define block_height heightd
+    %endif
 
-      ; reuse argument stack space
-      %define g_bilin_filterm x_offsetm
-      %define g_pw_8m y_offsetm
+    ; reuse argument stack space
+    %define g_bilin_filterm x_offsetm
+    %define g_pw_8m y_offsetm
 
-      ;Store bilin_filter and pw_8 location in stack
-      GET_GOT_NO_SAVE eax
+    ;Store bilin_filter and pw_8 location in stack
+    GET_GOT_NO_SAVE eax
 
-      lea ecx, [GLOBAL(bilin_filter_m)]
-      mov g_bilin_filterm, ecx
+    lea ecx, [GLOBAL(bilin_filter_m)]
+    mov g_bilin_filterm, ecx
 
-      lea ecx, [GLOBAL(pw_8)]
-      mov g_pw_8m, ecx
+    lea ecx, [GLOBAL(pw_8)]
+    mov g_pw_8m, ecx
 
-      LOAD_IF_USED 0, 1         ; load eax, ecx back
-    %endif
+    LOAD_ARG src, src_stride
   %else
     %if %2 == 1 ; avg
       cglobal sub_pixel_avg_variance%1xh, 7 + 2 * ARCH_X86_64, \
-                        7 + 2 * ARCH_X86_64, 13, src, src_stride, \
-                                             x_offset, y_offset, \
-                                             dst, dst_stride, \
-                                             sec, sec_stride, \
-                                             height, sse
+                        7 + 2 * ARCH_X86_64, 13, \
+                                      "p", src, "p-", src_stride, \
+                                      "d", x_offset, "d", y_offset, \
+                                      "p", dst, "p-", dst_stride, \
+                                      "p", sec, "p-", sec_stride, \
+                                      "d", height, "p", sse
       %if ARCH_X86_64
       %define block_height heightd
       %define sec_str sec_strideq
@@ -188,8 +183,11 @@ SECTION .text
       %define sec_str sec_stridemp
       %endif
     %else
-      cglobal sub_pixel_variance%1xh, 7, 7, 13, src, src_stride, x_offset, \
-                              y_offset, dst, dst_stride, height, sse
+      cglobal sub_pixel_variance%1xh, 7, 7, 13, \
+                                  "p", src, "p-", src_stride, \
+                                  "d", x_offset, "d", y_offset, \
+                                  "p", dst, "p-", dst_stride, \
+                                  "d", height, "p", sse
       %define block_height heightd
     %endif
 
diff --git a/vpx_dsp/x86/subtract_sse2.asm b/vpx_dsp/x86/subtract_sse2.asm
index 4273efb85..99c7570bc 100644
--- a/vpx_dsp/x86/subtract_sse2.asm
+++ b/vpx_dsp/x86/subtract_sse2.asm
@@ -19,9 +19,8 @@ SECTION .text
 
 INIT_XMM sse2
 cglobal subtract_block, 7, 7, 8, \
-                        rows, cols, diff, diff_stride, src, src_stride, \
-                        pred, pred_stride
-%define pred_str colsq
+                        "d", rows, "d", cols, "p", diff, "p-", diff_stride, \
+                        "p", src, "p-",src_stride, "p", pred, "p-", pred_stride
   pxor                  m7, m7         ; dedicated zero register
   cmp                colsd, 4
   je .case_4
@@ -31,7 +30,7 @@ cglobal subtract_block, 7, 7, 8, \
   je .case_16
   cmp                colsd, 32
   je .case_32
-
+ASSIGN_ARG pred_stride, cols
 %macro loop16 6
   mova                  m0, [srcq+%1]
   mova                  m4, [srcq+%2]
@@ -55,34 +54,34 @@ cglobal subtract_block, 7, 7, 8, \
   mova [diffq+mmsize*1+%6], m1
 %endmacro
 
-  mov             pred_str, pred_stridemp
+  LOAD_ARG pred_stride
 .loop_64:
   loop16 0*mmsize, 1*mmsize, 0*mmsize, 1*mmsize, 0*mmsize, 2*mmsize
   loop16 2*mmsize, 3*mmsize, 2*mmsize, 3*mmsize, 4*mmsize, 6*mmsize
   lea                diffq, [diffq+diff_strideq*2]
-  add                predq, pred_str
+  add                predq, pred_strideq
   add                 srcq, src_strideq
   dec                rowsd
   jg .loop_64
   RET
 
 .case_32:
-  mov             pred_str, pred_stridemp
+  LOAD_ARG pred_stride
 .loop_32:
   loop16 0, mmsize, 0, mmsize, 0, 2*mmsize
   lea                diffq, [diffq+diff_strideq*2]
-  add                predq, pred_str
+  add                predq, pred_strideq
   add                 srcq, src_strideq
   dec                rowsd
   jg .loop_32
   RET
 
 .case_16:
-  mov             pred_str, pred_stridemp
+  LOAD_ARG pred_stride
 .loop_16:
-  loop16 0, src_strideq, 0, pred_str, 0, diff_strideq*2
+  loop16 0, src_strideq, 0, pred_strideq, 0, diff_strideq*2
   lea                diffq, [diffq+diff_strideq*4]
-  lea                predq, [predq+pred_str*2]
+  lea                predq, [predq+pred_strideq*2]
   lea                 srcq, [srcq+src_strideq*2]
   sub                rowsd, 2
   jg .loop_16
@@ -92,7 +91,7 @@ cglobal subtract_block, 7, 7, 8, \
   movh                  m0, [srcq]
   movh                  m2, [srcq+src_strideq]
   movh                  m1, [predq]
-  movh                  m3, [predq+pred_str]
+  movh                  m3, [predq+pred_strideq]
   punpcklbw             m0, m7
   punpcklbw             m1, m7
   punpcklbw             m2, m7
@@ -104,24 +103,24 @@ cglobal subtract_block, 7, 7, 8, \
 %endmacro
 
 .case_8:
-  mov             pred_str, pred_stridemp
+  LOAD_ARG pred_stride
 .loop_8:
   loop_h
   lea                diffq, [diffq+diff_strideq*4]
   lea                 srcq, [srcq+src_strideq*2]
-  lea                predq, [predq+pred_str*2]
+  lea                predq, [predq+pred_strideq*2]
   sub                rowsd, 2
   jg .loop_8
   RET
 
 INIT_MMX
 .case_4:
-  mov             pred_str, pred_stridemp
+  LOAD_ARG pred_stride
 .loop_4:
   loop_h
   lea                diffq, [diffq+diff_strideq*4]
   lea                 srcq, [srcq+src_strideq*2]
-  lea                predq, [predq+pred_str*2]
+  lea                predq, [predq+pred_strideq*2]
   sub                rowsd, 2
   jg .loop_4
   RET
diff --git a/vpx_dsp/x86/vpx_convolve_copy_sse2.asm b/vpx_dsp/x86/vpx_convolve_copy_sse2.asm
index 9c5b414b4..559a90678 100644
--- a/vpx_dsp/x86/vpx_convolve_copy_sse2.asm
+++ b/vpx_dsp/x86/vpx_convolve_copy_sse2.asm
@@ -16,11 +16,13 @@ SECTION .text
 INIT_XMM sse2
 %ifidn %2, highbd
 %define pavg pavgw
-cglobal %2_convolve_%1, 4, 7, 4, src, src_stride, dst, dst_stride, \
+cglobal %2_convolve_%1, 4, 7, 4, "p", src, "p-", src_stride, \
+                                 "p", dst, "p-", dst_stride, \
                                  fx, fxs, fy, fys, w, h, bd
 %else
 %define pavg pavgb
-cglobal convolve_%1, 4, 7, 4, src, src_stride, dst, dst_stride, \
+cglobal convolve_%1, 4, 7, 4, "p", src, "p-", src_stride, \
+                              "p", dst, "p-", dst_stride, \
                               fx, fxs, fy, fys, w, h
 %endif
   mov r4d, dword wm
diff --git a/vpx_dsp/x86/vpx_subpixel_8t_ssse3.asm b/vpx_dsp/x86/vpx_subpixel_8t_ssse3.asm
index 3fbaa274c..a7518a2e7 100644
--- a/vpx_dsp/x86/vpx_subpixel_8t_ssse3.asm
+++ b/vpx_dsp/x86/vpx_subpixel_8t_ssse3.asm
@@ -97,7 +97,8 @@ SECTION .text
 ;-------------------------------------------------------------------------------
 %macro SUBPIX_HFILTER4 1
 cglobal filter_block1d4_%1, 6, 6+(ARCH_X86_64*2), 11, LOCAL_VARS_SIZE, \
-                            src, sstride, dst, dstride, height, filter
+                            "p", src, "p-", sstride, "p", dst, "p-", dstride, \
+                            "d", height, "p", filter
     mova                m4, [filterq]
     packsswb            m4, m4
 %if ARCH_X86_64
@@ -255,7 +256,8 @@ cglobal filter_block1d4_%1, 6, 6+(ARCH_X86_64*2), 11, LOCAL_VARS_SIZE, \
 ;-------------------------------------------------------------------------------
 %macro SUBPIX_HFILTER8 1
 cglobal filter_block1d8_%1, 6, 6+(ARCH_X86_64*1), 14, LOCAL_VARS_SIZE, \
-                            src, sstride, dst, dstride, height, filter
+                            "p", src, "p-", sstride, "p", dst, "p-", dstride, \
+                            "d", height, "p", filter
     mova                 m4, [filterq]
     SETUP_LOCAL_VARS
 %if ARCH_X86_64
@@ -362,7 +364,8 @@ cglobal filter_block1d8_%1, 6, 6+(ARCH_X86_64*1), 14, LOCAL_VARS_SIZE, \
 ;-------------------------------------------------------------------------------
 %macro SUBPIX_HFILTER16 1
 cglobal filter_block1d16_%1, 6, 6+(ARCH_X86_64*0), 14, LOCAL_VARS_SIZE, \
-                             src, sstride, dst, dstride, height, filter
+                             "p", src, "p-", sstride, "p", dst, "p-", dstride, \
+                             "d", height, "p", filter
     mova          m4, [filterq]
     SETUP_LOCAL_VARS
 .loop:
@@ -443,7 +446,8 @@ SUBPIX_HFILTER4  h8_avg
 ;-------------------------------------------------------------------------------
 %macro SUBPIX_VFILTER 2
 cglobal filter_block1d%2_%1, 6, 6+(ARCH_X86_64*3), 14, LOCAL_VARS_SIZE, \
-                             src, sstride, dst, dstride, height, filter
+                             "p", src, "p-", sstride, "p", dst, "p-", dstride, \
+                             "d", height, "p", filter
     mova          m4, [filterq]
     SETUP_LOCAL_VARS
 %if ARCH_X86_64
@@ -571,8 +575,8 @@ cglobal filter_block1d%2_%1, 6, 6+(ARCH_X86_64*3), 14, LOCAL_VARS_SIZE, \
 ;-------------------------------------------------------------------------------
 %macro SUBPIX_VFILTER16 1
 cglobal filter_block1d16_%1, 6, 6+(ARCH_X86_64*3), 14, LOCAL_VARS_SIZE, \
-                             src, sstride, dst, dstride, height, filter
-
+                             "p", src, "p-", sstride, "p", dst, "p-", dstride, \
+                             "d", height, "p", filter
     mova          m4, [filterq]
     SETUP_LOCAL_VARS
 %if ARCH_X86_64
-- 
2.16.4

